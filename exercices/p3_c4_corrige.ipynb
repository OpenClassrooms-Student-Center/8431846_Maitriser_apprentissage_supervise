{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "from settings import (\n",
    "    random_state,\n",
    "    PROJECT_PATH,\n",
    "    REGRESSION_TARGET,\n",
    "    CLASSIFICATION_TARGET,\n",
    ")\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "import mlflow\n",
    "from tqdm import tqdm\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "def perform_cross_validation(\n",
    "    X: pl.DataFrame,\n",
    "    y: pl.Series,\n",
    "    model,\n",
    "    cross_val_type,\n",
    "    scoring_metrics: tuple,\n",
    "    groups=None,\n",
    "):\n",
    "    scores = cross_validate(\n",
    "        model,\n",
    "        X.to_numpy(),\n",
    "        y.to_numpy(),\n",
    "        cv=cross_val_type,\n",
    "        return_train_score=True,\n",
    "        return_estimator=True,\n",
    "        scoring=scoring_metrics,\n",
    "        groups=groups,\n",
    "    )\n",
    "\n",
    "    scores_dict = {}\n",
    "    for metric in scoring_metrics:\n",
    "        scores_dict[\"average_train_\" + metric] = np.mean(scores[\"train_\" + metric])\n",
    "        scores_dict[\"train_\" + metric + \"_std\"] = np.std(scores[\"train_\" + metric])\n",
    "        scores_dict[\"average_test_\" + metric] = np.mean(scores[\"test_\" + metric])\n",
    "        scores_dict[\"test_\" + metric + \"_std\"] = np.std(scores[\"test_\" + metric])\n",
    "\n",
    "    model.fit(X.to_numpy(), y.to_numpy())\n",
    "\n",
    "    return scores, scores_dict, model\n",
    "\n",
    "\n",
    "# %%\n",
    "def get_features_most_importance(importances, feature_names, threshold=0.8):\n",
    "    sorted_indices = np.argsort(importances)\n",
    "    sorted_importances = importances[sorted_indices][::-1]\n",
    "    sorted_feature_names = [feature_names[i] for i in sorted_indices][::-1]\n",
    "\n",
    "    cumulated_importance = 0\n",
    "    important_features = []\n",
    "\n",
    "    for importance, feature_name in zip(sorted_importances, sorted_feature_names):\n",
    "        cumulated_importance += importance\n",
    "        important_features.append(feature_name)\n",
    "\n",
    "        if cumulated_importance >= threshold:\n",
    "            break\n",
    "\n",
    "    return important_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = pl.read_parquet(\n",
    "    os.path.join(PROJECT_PATH, \"transactions_post_feature_engineering.parquet\")\n",
    ")\n",
    "\n",
    "\n",
    "with open(\"features_used.json\", \"r\") as f:\n",
    "    feature_names = json.load(f)\n",
    "\n",
    "with open(\"categorical_features_used.json\", \"r\") as f:\n",
    "    categorical_features = json.load(f)\n",
    "\n",
    "numerical_features = [col for col in feature_names if col not in categorical_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_v1 = transactions.filter(pl.col(\"annee_transaction\") < 2020)\n",
    "\n",
    "transactions_v2 = transactions.filter(\n",
    "    pl.col(\"annee_transaction\").is_between(2020, 2021)\n",
    ")\n",
    "features_1 = [\n",
    "    \"type_batiment_Appartement\",\n",
    "    \"surface_habitable\",\n",
    "    \"prix_m2_moyen_mois_precedent\",\n",
    "    \"nb_transactions_mois_precedent\",\n",
    "    \"taux_interet\",\n",
    "    \"variation_taux_interet\",\n",
    "    \"acceleration_taux_interet\",\n",
    "]\n",
    "\n",
    "features_2 = features_1.extend([\"longitude\", \"latitude\", \"vefa\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nouvelle_acquitaine_experiment = client.set_experiment(\"Nouvelle-Aquitaine\")\n",
    "\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "\n",
    "\n",
    "with mlflow.start_run(run_name=\"catboost_\" + region) as run:\n",
    "        print(\n",
    "            \" ------------------Running Catboost Model for Region: \",\n",
    "            region + \"------------------\",\n",
    "        )\n",
    "        X = region_transactions_v1.drop(\n",
    "            [REGRESSION_TARGET, CLASSIFICATION_TARGET]\n",
    "        ).to_pandas()\n",
    "        y_classification = region_transactions_v1[CLASSIFICATION_TARGET].to_pandas()\n",
    "\n",
    "        catboost_model = CatBoostClassifier(random_state=random_state, verbose=False)\n",
    "        classification_scoring_metrics = [\"recall\", \"precision\", \"f1\"]\n",
    "\n",
    "        scores, scores_dict, catboost_model = perform_cross_validation(\n",
    "            X=X[features_1],\n",
    "            y=y_classification,\n",
    "            model=catboost_model,\n",
    "            cross_val_type=StratifiedKFold(),\n",
    "            scoring_metrics=classification_scoring_metrics,\n",
    "        )\n",
    "\n",
    "        mlflow.log_param(\"random_state\", random_state)\n",
    "        mlflow.log_param(\"features\", features_1)\n",
    "\n",
    "        for metric, value in scores_dict.items():\n",
    "            mlflow.log_metric(metric, value)\n",
    "\n",
    "        mlflow.sklearn.log_model(catboost_model, \"catboost_classifier\")\n",
    "\n",
    "        dataset_abstraction = mlflow.data.from_pandas(\n",
    "            region_transactions_v1.to_pandas()\n",
    "        )\n",
    "        mlflow.log_input(dataset_abstraction)\n",
    "\n",
    "    feature_importances = catboost_model.get_feature_importance(Pool(X[features_1]))\n",
    "    most_important_features = get_features_most_importance(\n",
    "        feature_importances, features_1\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "best_run = client.search_runs(\n",
    "    experiment_id, order_by=[\"metrics.val_loss ASC\"], max_results=1\n",
    ")[0]\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
