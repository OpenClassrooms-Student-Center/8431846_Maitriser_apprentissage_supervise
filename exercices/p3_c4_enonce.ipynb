{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from settings import (\n",
    "    random_state,\n",
    "    PROJECT_PATH,\n",
    "    REGRESSION_TARGET,\n",
    "    CLASSIFICATION_TARGET,\n",
    ")\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "import mlflow\n",
    "from mlflow import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cross_validation(\n",
    "    X: pl.DataFrame,\n",
    "    y: pl.Series,\n",
    "    model,\n",
    "    cross_val_type,\n",
    "    scoring_metrics: tuple,\n",
    "    groups=None,\n",
    "):\n",
    "    scores = cross_validate(\n",
    "        model,\n",
    "        X.to_numpy(),\n",
    "        y.to_numpy(),\n",
    "        cv=cross_val_type,\n",
    "        return_train_score=True,\n",
    "        return_estimator=True,\n",
    "        scoring=scoring_metrics,\n",
    "        groups=groups,\n",
    "    )\n",
    "\n",
    "    scores_dict = {}\n",
    "    for metric in scoring_metrics:\n",
    "        scores_dict[\"average_train_\" + metric] = np.mean(scores[\"train_\" + metric])\n",
    "        scores_dict[\"train_\" + metric + \"_std\"] = np.std(scores[\"train_\" + metric])\n",
    "        scores_dict[\"average_test_\" + metric] = np.mean(scores[\"test_\" + metric])\n",
    "        scores_dict[\"test_\" + metric + \"_std\"] = np.std(scores[\"test_\" + metric])\n",
    "\n",
    "    model.fit(X.to_numpy(), y.to_numpy())\n",
    "\n",
    "    return scores, scores_dict, model\n",
    "\n",
    "def get_features_most_importance(importances, feature_names, threshold=0.8):\n",
    "    sorted_indices = np.argsort(importances)\n",
    "    sorted_importances = importances[sorted_indices][::-1]\n",
    "    sorted_feature_names = [feature_names[i] for i in sorted_indices][::-1]\n",
    "\n",
    "    cumulated_importance = 0\n",
    "    important_features = []\n",
    "\n",
    "    for importance, feature_name in zip(sorted_importances, sorted_feature_names):\n",
    "        cumulated_importance += importance\n",
    "        important_features.append(feature_name)\n",
    "\n",
    "        if cumulated_importance >= threshold:\n",
    "            break\n",
    "\n",
    "    return important_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = pl.read_parquet(\n",
    "    os.path.join(PROJECT_PATH, \"transactions_post_feature_engineering.parquet\")\n",
    ")\n",
    "\n",
    "\n",
    "with open(\"../features_used.json\", \"r\") as f:\n",
    "    feature_names = json.load(f)\n",
    "\n",
    "with open(\"../categorical_features_used.json\", \"r\") as f:\n",
    "    categorical_features = json.load(f)\n",
    "\n",
    "numerical_features = [col for col in feature_names if col not in categorical_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_v1 = transactions.filter(pl.col(\"annee_transaction\") < 2020)\n",
    "\n",
    "transactions_v2 = transactions.filter(\n",
    "    pl.col(\"annee_transaction\").is_between(2020, 2021)\n",
    ")\n",
    "features_1 = [\n",
    "    \"type_batiment_Appartement\",\n",
    "    \"surface_habitable\",\n",
    "    \"prix_m2_moyen_mois_precedent\",\n",
    "    \"nb_transactions_mois_precedent\",\n",
    "    \"taux_interet\",\n",
    "    \"variation_taux_interet\",\n",
    "    \"acceleration_taux_interet\",\n",
    "]\n",
    "\n",
    "features_2 = features_1 + [\"longitude\", \"latitude\", \"vefa\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Attention : </b> Assurez-vous de lancer ce code dans le même dossier où les modèles pré-covid ont été créés ! En effet, quand vous lancez votre MLflow UI (ainsi qu'un objet MlflowClient) sans arguments supplémentaires, le package va utiliser comme modèle registry ceux du dossier actuel. Plus précisement, Mlflow va créer un dossier mlruns, où seront stockés tous vos modèles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il suffit alors de : \n",
    "* lancer dans votre Terminal la commande mlflow ui en précisant l'adresse du dossier mlruns comme ceci : mlflow ui --backend-store-uri adresse_de_votre_choix\n",
    "* Réaliser la même opération côté Python avec la commande mlflow.set_tracking_uri(\"adresse_de_votre_choix\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
