{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bentoml\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce corrigé, nous allons principalement nous concentrer sur le code du service (à stocker dans un fichier service.py ou avec un autre nommage )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En premier lieu, nous définissons la liste des régions de notre périmètre\n",
    "regions = [\"Auvergne-Rhône-Alpes\", \"Île-de-France\", \"Nouvelle-Aquitaine\", \"Occitanie\",\"Provence-Alpes-Côte d'Azur\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, nous définissons notre service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bentoml.service()\n",
    "class TransactionPredictionRegion:\n",
    "    \n",
    "\n",
    "    def __init__(self):\n",
    "        transaction_classifiers = { region :\n",
    "            bentoml.models.get(\n",
    "        \"transaction_below_market_identifier_{region}:latest\"\n",
    "    ) for region in list_regions\n",
    "        }\n",
    "        transaction_regressors = { region :\n",
    "            bentoml.models.get(\n",
    "        \"transaction_value_estimator_{region}:latest\"\n",
    "    ) for region in list_regions\n",
    "        }\n",
    "\n",
    "    @bentoml.api\n",
    "    def predict(self, region, transactions: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "        \n",
    "        self.classifier = bentoml.sklearn.load_model(self.transaction_classifiers[region])\n",
    "        self.regressor = bentoml.sklearn.load_model(self.transaction_regressors[region])\n",
    "        predicted_classes = self.classifier.predict(transactions)\n",
    "        predicted_transactions = self.regressor.predict(transactions)\n",
    "        return (predicted_transactions, predicted_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deux approches (entre autres) sont possibles : \n",
    "* Dès que le service sera lancé (avec la commande bentoml serve), tous les modèles (5 de classification et 5 de régression) seront d'abord chargés. C'est ce que nous avons fait ici. \n",
    "* Nous ne chargeons que les 2 modèles pertinents, au moment où un utilisateur appelle l'API pour l'inférence\n",
    "\n",
    "Il n'y a pas de bons choix dans l'absolu, tout dépend des contraintes de projet (en termes de vitesse de réponse souhaitée de l'API, du volume du trafic que l'API va encaisser, etc.). \n",
    "\n",
    "Ici, nous avons procédé avec la 1ere approche, car les modèles sont relativement légers et que nous avons peu de régions.\n",
    "\n",
    "Une approche plus scalable serait d'avoir plusieurs instances actives de la même API, chacune servant une région "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vu la définition du endpoint, il est attendu à ce que nous fournissions comme input une région et un ensemble d'observations sous la forme d'un numpy array. Nous pouvons, comme vu dans le cours, \n",
    "* Utiliser le terminal avec curl \n",
    "* Utiliser le Swagger UI \n",
    "* Utiliser Python, avec la librairie requests directement ou indirectement via BentoMl (comme fait ci-dessous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Après avoir lancé la commande bentoml serve, nous pouvons intéragir avec\n",
    "le modèle en précisant la région et les transactions à prédire.\n",
    "'''\n",
    "\n",
    "with bentoml.SyncHTTPClient(\"http://localhost:3000\") as client:\n",
    "    result = client.predict(region = \"Occitanie\", transactions=test_values)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
