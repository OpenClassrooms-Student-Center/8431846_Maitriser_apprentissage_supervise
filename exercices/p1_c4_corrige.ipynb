{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import polars as pl \n",
    "import sys \n",
    "import json \n",
    "import numpy as np\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from settings import (\n",
    "    REGRESSION_TARGET,CLASSIFICATION_TARGET, random_state, PROJECT_PATH\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import cross_validate, TimeSeriesSplit\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = pl.read_parquet(\n",
    "    os.path.join(PROJECT_PATH, \"transactions_post_feature_engineering.parquet\")\n",
    ")\n",
    "\n",
    "with open(\"../features_used.json\", \"r\") as f:\n",
    "    feature_names = json.load(f)\n",
    "\n",
    "# %%\n",
    "selected_region = \"nom_region_Occitanie\"\n",
    "region_transactions = transactions.filter(pl.col(selected_region) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = region_transactions.drop([REGRESSION_TARGET, CLASSIFICATION_TARGET])\n",
    "y_classification = region_transactions[CLASSIFICATION_TARGET]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cross_validation(\n",
    "    X: pl.DataFrame,\n",
    "    y: pl.Series,\n",
    "    model,\n",
    "    cross_val_type,\n",
    "    scoring_metrics: tuple,\n",
    "    return_estimator=False,\n",
    "    groups=None,\n",
    "):\n",
    "    scores = cross_validate(\n",
    "        model,\n",
    "        X.to_numpy(),\n",
    "        y.to_numpy(),\n",
    "        cv=cross_val_type,\n",
    "        return_train_score=True,\n",
    "        return_estimator=return_estimator,\n",
    "        scoring=scoring_metrics,\n",
    "        groups=groups,\n",
    "    )\n",
    "\n",
    "    for metric in scoring_metrics:\n",
    "        print(\n",
    "            \"Average Train {metric} : {metric_value}\".format(\n",
    "                metric=metric,\n",
    "                metric_value=np.mean(scores[\"train_\" + metric]),\n",
    "            )\n",
    "        )\n",
    "        print(\n",
    "            \"Train {metric} Standard Deviation : {metric_value}\".format(\n",
    "                metric=metric, metric_value=np.std(scores[\"train_\" + metric])\n",
    "            )\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            \"Average Test {metric} : {metric_value}\".format(\n",
    "                metric=metric, metric_value=np.mean(scores[\"test_\" + metric])\n",
    "            )\n",
    "        )\n",
    "        print(\n",
    "            \"Test {metric} Standard Deviation : {metric_value}\".format(\n",
    "                metric=metric, metric_value=np.std(scores[\"test_\" + metric])\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ce serait une erreur de travailler avec une donnée non-triée quand on veut utiliser cette variante\n",
    "X = X.sort([\"annee_transaction\", \"mois_transaction\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_classifier = XGBClassifier(random_state=random_state)\n",
    "classification_scoring_metrics = (\"precision\", \"recall\", \"roc_auc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TimeSeriesSplit() est une méthode de validation croisée utilisée pour évaluer la performance d'un modèle sur des données avec une dimension temporelle. Elle divise les données en segments temporels non chevauchant, en utilisant les données du passé pour prédire les données du futur.\n",
    "\n",
    "Lorsque vous utilisez TimeSeriesSplit(), vous spécifiez le nombre de splits (ou folds) que vous souhaitez créer. Par exemple, si vous avez 10 splits, votre jeu de données sera divisé en 10 segments temporels.\n",
    "\n",
    "Le premier split utilise les données du début du jeu de données pour l'entraînement et les données suivantes pour le test. Le deuxième split utilise les données du début jusqu'à la fin du premier split pour l'entraînement et les données suivantes pour le test. Cette méthode est répétée jusqu'à ce que tous les splits soient créés.\n",
    "\n",
    "Cela permet d'évaluer la performance du modèle sur des données futures, en s'assurant qu'il n'a pas accès à des informations sur le futur lors de la phase d'entraînement. Cela est particulièrement important pour les données temporelles, car les modèles doivent être capables de prédire l'avenir en se basant sur les données du passé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train precision : 0.805238579824026\n",
      "Train precision Standard Deviation : 0.025844640476000855\n",
      "Average Test precision : 0.4080283232385069\n",
      "Test precision Standard Deviation : 0.020898104786274272\n",
      "Average Train recall : 0.5052595507758886\n",
      "Train recall Standard Deviation : 0.11411039229388611\n",
      "Average Test recall : 0.2565957137562226\n",
      "Test recall Standard Deviation : 0.05806081128105084\n",
      "Average Train roc_auc : 0.8299132079107723\n",
      "Train roc_auc Standard Deviation : 0.0448855972797487\n",
      "Average Test roc_auc : 0.4942290932104174\n",
      "Test roc_auc Standard Deviation : 0.007638449053208446\n"
     ]
    }
   ],
   "source": [
    "scores_xgboost = perform_cross_validation(\n",
    "    X=X[[col for col in feature_names if col in X.columns]],\n",
    "    y=y_classification,\n",
    "    model=xgboost_classifier,\n",
    "    cross_val_type=TimeSeriesSplit(), #Par défaut, le nombre de folds est 5\n",
    "    scoring_metrics=classification_scoring_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A premier abord, nous avons une dégradation considérable de la performance du modèle en test, ce qui suggère un fort overfit et une incapacité de prédire le contexte immobilier changeant avec le temps. Cela pourrait signifier que notre modèle nécéssiterait un réentrainement régulier, ou un feature engineering plus riche pour prendre en considération des informations invisibles au modèle aujourd'hui. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nous souhaitons pousser l'analyse plus loin, il faudrait regarder les dates exactes de début et de fin de chaque fold et regarder à quel point le contexte de la donnée à changé ! Nous savons que notre jeu de données couvre la période Juin 2018-Decembre 2022. Entre le covid et l'inflation qui a suivi, on est sur que les folds vont avoir des contextes immobiliers très différents. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Malheureusement, la fonction cross_validate ne permets pas cela ! Il faudrait utiliser une fonction avec une boucle for comme celle ci-dessous. Cela permetrait de récupérer les indices des lignes et d'analyser les périodes temporelles ainsi que leurs features en détail "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit()\n",
    "for i, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Test:  index={test_index}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
